{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the MPC's Isolated Tracklet File\n",
    "#### Matthew J. Holman\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 November 2017\n",
    "\n",
    "I am using this notebook as a starting point for the cs182 final project to link the ITF.\n",
    "\n",
    "The plan is to:\n",
    "\n",
    "    * Get the ITF records into a reasonable format, with the observatory locations determined, the time converted to jd_utc, jd_ut1, and jd_tdb, and the RA/Dec converted to unit vectors.\n",
    "    * We need to keep the original format lines around, for later orbit fitting.\n",
    "    * Separate the tracklets into months between successive full moons.\n",
    "    * Determine the healpix region for each tracklet\n",
    "    * Transform the tracklets in each time/healpix block into a local projection\n",
    "    * Do the linear fit for each tracklet to get the a, b, g, adot, bdot solutions\n",
    "    * Look for clusters in those solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The NOVAS package\n",
    "\n",
    "First, get the USNO's python NOVAS package.  We'll need that.\n",
    "\n",
    "http://aa.usno.navy.mil/software/novas/novas_py/novaspy_intro.php\n",
    "\n",
    "Just type \n",
    "\n",
    "pip install novas\n",
    "\n",
    "pip install novas_de405\n",
    "\n",
    "Here's the reference:\n",
    "\n",
    "Barron, E. G., Kaplan, G. H., Bangert, J., Bartlett, J. L., Puatua, W., Harris, W., & Barrett, P. (2011) “Naval Observatory Vector Astrometry Software (NOVAS) Version 3.1, Introducing a Python Edition,” Bull. AAS, 43, 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The kepcart library\n",
    "\n",
    "You will need to make sure you have a copy of the kepcart library.  There is a copy of it on the MPC bitbucket site, with some instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import math\n",
    "import kepcart as kc\n",
    "import healpy as hp\n",
    "import collections\n",
    "import astropy\n",
    "from collections import defaultdict\n",
    "import MPC_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Observatories = MPC_library.Observatories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ObservatoryXYZ = Observatories.ObservatoryXYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22807555,  0.87911034,  0.38114111])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Observatories.getObservatoryPosition('F51', 2457000.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed the 2-line observations, for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Observatories.getObservatoryPosition('C51', 2457000.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reading the MPC observation files\n",
    "\n",
    "Dealing with files line by line in python is not fast.  \n",
    "\n",
    "The itf.txt, NumObs.txt, and UnnObs.txt files have a mix of 1-line and 2-line formats.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This routine checks the 80-character input line to see if it contains a special character (S, R, or V) that indicates a 2-line \n",
    "# record.\n",
    "def is_two_line(line):\n",
    "    note2 = line[14]\n",
    "    return note2=='S' or note2=='R' or note2=='V'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This routine opens and reads filename, separating the records into those in the 1-line and 2-line formats.\n",
    "# The 2-line format lines are merged into single 160-character records for processing line-by-line.\n",
    "def split_MPC_file(filename):\n",
    "    filename_1_line = filename.rstrip('.txt')+\"_1_line.txt\"\n",
    "    filename_2_line = filename.rstrip('.txt')+\"_2_line.txt\"\n",
    "    with open(filename_1_line, 'w') as f1_out, open(filename_2_line, 'w') as f2_out:\n",
    "        line1=None\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                if is_two_line(line):\n",
    "                    line1=line\n",
    "                    continue\n",
    "                if line1 != None:\n",
    "                    merged_lines = line1.rstrip('\\n') + line\n",
    "                    f2_out.write(merged_lines)\n",
    "                    line1 = None\n",
    "                else:\n",
    "                    f1_out.write(line)\n",
    "                    line1 = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split the files for the three main MPC observation files.  (Need to convert the section below to code from markdown, if you haven't run it already.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "split_MPC_file('itf_new.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are routines that read the files after they have been split into their respective formats.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readMPC_1_line(filename='NumObs_1_line.txt', nrows=1000000):\n",
    "    colspecs = [(0, 5), (5, 12), (12, 13), (13, 14), (14, 15), (15, 32), (32, 44), (44, 56), (65, 71), (77, 80)]\n",
    "    colnames = ['objName', 'provDesig', 'disAst', 'note1', 'note2', 'dateObs', 'RA', 'Dec', 'MagFilter', 'obsCode']\n",
    "    df = pd.read_fwf(filename, colspecs=colspecs, names=colnames, header=None, nrows=nrows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertObs80(line):\n",
    "    objName   = line[0:5]\n",
    "    provDesig = line[5:12]\n",
    "    disAst    = line[12:13]\n",
    "    note1     = line[13:14]\n",
    "    note2     = line[14:15]\n",
    "    dateObs   = line[15:32]\n",
    "    RA        = line[32:44]\n",
    "    Dec       = line[44:56]\n",
    "    mag       = line[65:70]\n",
    "    filt      = line[70:71]\n",
    "    obsCode   = line[77:80]\n",
    "    return objName, provDesig, disAst, note1, note2, dateObs, RA, Dec, mag, filt, obsCode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitMagFilter(magFilter):\n",
    "    pieces = magFilter.split()\n",
    "    if len(pieces)==0:\n",
    "        return None, None\n",
    "    elif len(pieces)==1:\n",
    "         return pieces[0], None\n",
    "    else:\n",
    "        return pieces[0], pieces[1]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "N = 10\n",
    "with open('itf_new_1_line.txt', 'r') as f:\n",
    "    lines = [next(f) for x in range(N)]\n",
    "    for line in lines:\n",
    "        objName, provDesig, disAst, note1, note2, dateObs, RA, Dec, mag, filt, obsCode = convertObs80(line)\n",
    "        jd_utc = MPC_library.date2JD(dateObs)\n",
    "        jd_tdb  = MPC_library.EOP.jdTDB(jd_utc)\n",
    "        xh, yh, zh = Observatories.getObservatoryPosition(obsCode, jd_utc)\n",
    "        raDeg, decDeg = MPC_library.RA2degRA(RA), MPC_library.Dec2degDec(Dec)\n",
    "        x = np.cos(decDeg*np.pi/180.)*np.cos(raDeg*np.pi/180.)\n",
    "        y = np.cos(decDeg*np.pi/180.)*np.sin(raDeg*np.pi/180.)  \n",
    "        z = np.sin(decDeg*np.pi/180.)\n",
    "        if len(filt.split())==0:\n",
    "            filt = '-'\n",
    "        if len(filt.split())==0:\n",
    "            filt = '-'\n",
    "        #mag, filt = splitMagFilter(magFilter)\n",
    "        print(\"%7s %s %13.6lf %13.6lf %11.6lf %11.6lf %11.6lf %11.6lf %11.6lf %11.6lf %11.6lf %11.6lf %s %s\"% \\\n",
    "              (provDesig, dateObs, jd_utc, jd_tdb, MPC_library.RA2degRA(RA), MPC_library.Dec2degDec(Dec), x, y, z, xh, yh, zh, mag, filt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am generating a version of the MPC data that includes just the few string-like fields at the start of each line, followed by jd_tdb, the unit vector to the observed target, and the heliocentric position vector of the observatory at that time."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "with open('itf_new_1_line.mpc', 'w') as outfile:\n",
    "    with open('itf_new_1_line.txt', 'r') as f:\n",
    "        outstring = \"#trackletID yr   mn dy      obsCode mag filter  jd_tdb       x_target     y_target     z_target      x_obs       y_obs        z_obs     \\n\"\n",
    "        outfile.write(outstring)\n",
    "        for line in f:\n",
    "            objName, provDesig, disAst, note1, note2, dateObs, RA, Dec, mag, filt, obsCode = convertObs80(line)\n",
    "            jd_utc = MPC_library.date2JD(dateObs)\n",
    "            jd_tdb  = MPC_library.EOP.jdTDB(jd_utc)\n",
    "            raDeg, decDeg = MPC_library.RA2degRA(RA), MPC_library.Dec2degDec(Dec)\n",
    "            x = np.cos(decDeg*np.pi/180.)*np.cos(raDeg*np.pi/180.)\n",
    "            y = np.cos(decDeg*np.pi/180.)*np.sin(raDeg*np.pi/180.)  \n",
    "            z = np.sin(decDeg*np.pi/180.)\n",
    "            if filt.isspace():\n",
    "                filt = '-'\n",
    "            if mag.isspace():\n",
    "                mag = '----'\n",
    "            xh, yh, zh = Observatories.getObservatoryPosition(obsCode, jd_utc)\n",
    "            outstring = \"%11s %s %4s %5s %s %13.6lf %12.7lf %12.7lf %12.7lf %12.6lf %12.7lf %12.7lf\\n\"% \\\n",
    "                  (provDesig, dateObs, obsCode, mag, filt, jd_tdb, x, y, z, xh, yh, zh)\n",
    "            outfile.write(outstring)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS0051 had a typo on the magnitude, a missing '.' in the number.  I corrected that manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to preserve tracklets across the time and space boundaries.  That means that the division into time slices and spatial regions should be based on the first member of a tracklet only.  That way the full tracklet is accepted or not, rather than pieces occasionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sorted_tracklets(itf_filename):\n",
    "    tracklets = defaultdict(list)\n",
    "    tracklets_jd_dict = {}\n",
    "    with open(itf_filename) as infile:\n",
    "        for line in infile:\n",
    "            if not line.startswith('#'):\n",
    "                desig = line[0:12]\n",
    "                jd_tdb = float(line[43:57])\n",
    "                if desig not in tracklets_jd_dict:\n",
    "                    # Got a new tracklet\n",
    "                    tracklets_jd_dict[desig] = jd_tdb\n",
    "                tracklets[desig].append(line)\n",
    "    sortedTrackletKeys = sorted(tracklets.keys(), key=lambda k: tracklets_jd_dict[k]) \n",
    "    return tracklets, tracklets_jd_dict, sortedTrackletKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    JH012    2433421.986183\n",
      "    JUAN067  2433868.078846\n",
      "    ML51000  2433926.060067\n",
      "    q00O07S  2434036.06343\n",
      "    GVWFM1   2434271.92449\n",
      "    APS2     2434413.993494\n",
      "    APS1     2434413.993494\n",
      "    q00WI0O  2435134.903228\n",
      "    q80A00B  2435207.861012\n",
      "    RH01     2435572.063148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3884178"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracklets, tracklets_jd_dict, sortedTracklets = get_sorted_tracklets('itf_new_1_line.mpc')\n",
    "\n",
    "for k in sortedTracklets[:10]:\n",
    "    print(k, tracklets_jd_dict[k])    \n",
    "\n",
    "len(sortedTracklets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K14R17Q_001  2434686.899433\n",
      "PLS6331_001  2437230.019837\n",
      "K04R80Q_001  2437230.096228\n",
      "PLS4702_001  2437230.096228\n",
      "K04R80Q_002  2437230.999708\n",
      "PLS6331_002  2437231.964299\n",
      "PLS4702_002  2437232.02403\n",
      "PLS4702_003  2437233.051132\n",
      "K04R80Q_003  2437234.016413\n",
      "PLS6331_003  2437234.016413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "243721"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UnnObs_tracklets, UnnObs_tracklets_jd_dict, UnnObs_sortedTracklets = get_sorted_tracklets('UnnObs_Training_1_line_A.mpc')\n",
    "\n",
    "for k in UnnObs_sortedTracklets[:10]:\n",
    "    print(k, UnnObs_tracklets_jd_dict[k])    \n",
    "\n",
    "len(UnnObs_sortedTracklets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2431173.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the jd of new moon, to the nearest half day\n",
    "def lunation_center(n, tref=2457722.0125, p=29.49791666663562):\n",
    "    t = tref + p*n\n",
    "    tp = np.floor(t) + 0.5\n",
    "    return tp\n",
    "\n",
    "lunation_center(-900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweep through the tracklets once, outputting them into a sequence of overlapping time ranges.\n",
    "\n",
    "Set n_begin to a small value\n",
    "Read a tracklet, which are in ascending date order.\n",
    "\n",
    "If the date for the tracklet is bigger than the upper date value for n_begin, advance n_begin until the date of the tracklet is withi the upper date value. \n",
    "\n",
    "for n in range(n_begin, n_end), \n",
    "if the date for the tracklet is within the date range corresponding to time center n, then processing the tracklet using time center n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_time_windows(tracklets, sortedTracklets, tracklets_jd_dict, file_stem='itf_new_1_line.mpc', n_begin=-825, n_end=14, dt=45.):\n",
    "    t_center = lunation_center(n_begin)\n",
    "    files = {}\n",
    "\n",
    "    header='#trackletID yr   mn dy      obsCode mag filter  jd_tdb       x_target     y_target     z_target      x_obs       y_obs        z_obs     '\n",
    "\n",
    "    for desig in sortedTracklets:\n",
    "        jd_tdb = tracklets_jd_dict[desig]\n",
    "        while(jd_tdb>t_center+dt):\n",
    "            if n_begin in files:\n",
    "                files[n_begin].close()\n",
    "            n_begin +=1\n",
    "            t_center = lunation_center(n_begin)\n",
    "        for n in range(n_begin, n_end):\n",
    "            if jd_tdb<lunation_center(n)-dt:\n",
    "                break\n",
    "            if n not in files:\n",
    "                outfile = file_stem.rstrip('.mpc')+'_'+str(lunation_center(n))+'_pm'+str(dt)+'.mpc'\n",
    "                files[n] = open(outfile, 'w')\n",
    "                files[n].write(header+'\\n')\n",
    "            for line in tracklets[desig]:\n",
    "                files[n].write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "separate_time_windows(tracklets, sortedTracklets, tracklets_jd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "separate_time_windows(tracklets, sortedTracklets, tracklets_jd_dict, dt=15.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "separate_time_windows(UnnObs_tracklets, UnnObs_sortedTracklets, UnnObs_tracklets_jd_dict, file_stem='UnnObs_Training_1_line_A.mpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This returns the topocentric distances and new heliocentric\n",
    "# position vectors to the target, given the assumed distance\n",
    "# r and the position vector of the observatory re.\n",
    "def adjust_position(r, rho_target, re):\n",
    "    rho_x, rho_y, rho_z = rho_target\n",
    "    xe, ye, ze = re\n",
    "    Robs = np.sqrt(xe * xe + ye * ye + ze * ze)\n",
    "    cos_phi = -(rho_x * xe + rho_y * ye + rho_z * ze) / Robs\n",
    "    phi = np.arccos(cos_phi)\n",
    "    sin_phi = np.sin(phi)\n",
    "\n",
    "    xx2 = r*r - Robs*sin_phi * Robs*sin_phi\n",
    "    \n",
    "    if xx2 < 0:\n",
    "        None, None\n",
    "\n",
    "    xx = np.sqrt(xx2)\n",
    "    yy = Robs * cos_phi\n",
    "    \n",
    "    rho_p = yy + xx\n",
    "\n",
    "    # This could be done with numpy arrays\n",
    "    x_p = xe + rho_p*rho_x\n",
    "    y_p = ye + rho_p*rho_y\n",
    "    z_p = ze + rho_p*rho_z\n",
    "    \n",
    "    rho_m = yy - xx\n",
    "    \n",
    "    # This could be done with numpy arrays    \n",
    "    x_m = xe + rho_m*rho_x\n",
    "    y_m = ye + rho_m*rho_y\n",
    "    z_m = ze + rho_m*rho_z\n",
    "        \n",
    "    return (rho_p, (x_p, y_p, z_p)), (rho_m, (x_m, y_m, z_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does the transformations on the data using the date of the n-th new\n",
    "# moon as the reference time.\n",
    "#\n",
    "# It is reading and processing the entire *.mpc file.\n",
    "#\n",
    "# This does the heliocentric tranformation for the assumed radius function,\n",
    "# r_func.\n",
    "# It then does light-time correction.\n",
    "# direction.  This is ok for the time span we are considering.\n",
    "# \n",
    "# This generates a file called *.trans, and it incorporates\n",
    "# the distance assumed in the file name.\n",
    "#\n",
    "def transform_positions(n, r_func, file_stem='itf_new_1_line.mpc', dt=45.):\n",
    "    infilename = file_stem.rstrip('.mpc')+'_'+str(lunation_center(n))+'_pm'+str(dt)+'.mpc'\n",
    "    try:\n",
    "      open(infilename, 'r')\n",
    "    except IOError:\n",
    "      return 0    \n",
    "    t_ref = lunation_center(n)\n",
    "    r_ref = r_func(t_ref)\n",
    "    r_name = \"_r%.1lf\" % (r_ref)\n",
    "    outfilename = file_stem.rstrip('.mpc')+'_'+str(lunation_center(n))+'_pm'+str(dt)+r_name+'.trans'\n",
    "    \n",
    "    nside = 32\n",
    "    \n",
    "    #rot_mat = MPC_library.rotate_matrix(-MPC_library.Constants.ecl)\n",
    "    \n",
    "    with open(infilename, 'r') as infile, open(outfilename, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            if line.startswith('#'): \n",
    "                header = line.rstrip()\n",
    "                outfile.write(header + '          dt         x_cor       y_cor        z_cor       pix \\n')\n",
    "            else:\n",
    "                lineID = line[:43]\n",
    "\n",
    "                jd_tdb = float(line[43:57])\n",
    "\n",
    "                x_target, y_target, z_target = line[57:97].split()\n",
    "                r_target = np.array([float(x_target), float(y_target), float(z_target)])\n",
    "\n",
    "                x_obs, y_obs, z_obs = line[97:135].split()            \n",
    "                r_obs = np.array([float(x_obs), float(y_obs), float(z_obs)])\n",
    "\n",
    "                # Adjust positions\n",
    "                dt = 0.0\n",
    "                r_prev = r_func(jd_tdb-dt)\n",
    "                rho_r_p, rho_r_m = adjust_position(r_prev, r_target, r_obs)\n",
    "                dt = rho_r_p[0]/MPC_library.Constants.speed_of_light\n",
    "                \n",
    "                # Do light-time iterations.\n",
    "                # Probably don't need to do this at this point, because it is\n",
    "                # being re-done in a later step.  Removing this will remove\n",
    "                # an iterative step.                \n",
    "                ''''\n",
    "                i=0\n",
    "                while(np.abs(r_func(jd_tdb-dt)-r_prev)>1e-8):\n",
    "                    rho_r_p, rho_r_m = adjust_position(r_prev, r_target, r_obs)\n",
    "                    dt = rho_r_p[0]/MPC_library.Constants.speed_of_light\n",
    "                    r_prev = r_func(jd_tdb-dt)\n",
    "                    i += 1\n",
    "                '''\n",
    "\n",
    "                x, y, z = rho_r_p[1]\n",
    "                \n",
    "                # At this point, I think I should fit a line \n",
    "                # to the x, y, z components of each tracklet,\n",
    "                # vs jd_tdb-dt-t_ref\n",
    "                # rather than waiting for a later processing stage.\n",
    "                # Then I'll have both a position and velocity vector.\n",
    "            \n",
    "                # Below is a simple gravitational acceleration correction\n",
    "                # that I found to be completely unimportant.\n",
    "                '''\n",
    "                r2 = x*x + y*y + z*z\n",
    "                r3 = r2*np.sqrt(r2)\n",
    "                fac = MPC_library.Constants.GMsun/r3\n",
    "                acc_x, acc_y, acc_z = -fac*x, -fac*y, -fac*z\n",
    "                t_elap = jd_tdb-dt - t_ref\n",
    "                dx = 0.5*acc_x*t_elap*t_elap\n",
    "                dy = 0.5*acc_y*t_elap*t_elap\n",
    "                dz = 0.5*acc_z*t_elap*t_elap\n",
    "            \n",
    "                #pos = np.array([x-dx, y-dy, z-dz])\n",
    "                \n",
    "                # Could rotate to ecliptic coordinates\n",
    "                \n",
    "                #ecl_pos = np.dot(rot_mat, pos.T).T\n",
    "                #xp, yp, zp = ecl_pos\n",
    "                \n",
    "                xp, yp, zp = x-dx, y-dy, z-dz\n",
    "                '''\n",
    "                \n",
    "                xp, yp, zp = x, y, z\n",
    "                \n",
    "                pix = hp.vec2pix(nside, xp, yp, zp, nest=True)\n",
    "            \n",
    "                outstring = line.rstrip() + \" %13.6lf %12.7lf %12.7lf %12.7lf %5d\\n\"% \\\n",
    "                      (dt, xp, yp, zp, pix)\n",
    "\n",
    "                outfile.write(outstring)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## The time required is mostly file I/O\n",
    "for n in range(-825,14):\n",
    "    transform_positions(n, lambda t: 2.5 + 0e-4*(t-lunation_center(10)), dt=45.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The time required is mostly file I/O\n",
    "for n in range(-825,14):\n",
    "    transform_positions(n, lambda t: 2.5 + 0e-4*(t-lunation_center(10)), dt=15.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(-825,14):\n",
    "    transform_positions(n, lambda t: 2.5 + 0e-4*(t-lunation_center(10)), file_stem='UnnObs_Training_1_line_A.mpc', dt=45.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform_tracklets(tracklets, sortedTracklets, tracklets_jd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(-20,15):\n",
    "    print(n, lunation_center(n), MPC_library.getEarthPosition(lunation_center(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_tracklets(UnnObs_tracklets, UnnObs_sortedTracklets, UnnObs_tracklets_jd_dict, file_stem='UnnObs_Training_1_line_A.mpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xyz_to_proj_matrix(r_ref):\n",
    "    x_ref, y_ref, z_ref = r_ref\n",
    "    r = np.sqrt(x_ref*x_ref + y_ref*y_ref + z_ref*z_ref)\n",
    "    lon0 = np.arctan2(y_ref, x_ref)\n",
    "    lat0 = np.arcsin(z_ref/r)\n",
    "    slon0 = np.sin(lon0)\n",
    "    clon0 = np.cos(lon0)\n",
    "    slat0 = np.sin(lat0)\n",
    "    clat0 = np.cos(lat0)\n",
    "\n",
    "    mat = np.array([[-slon0, clon0, 0], \n",
    "                    [-clon0*slat0, -slon0*slat0, clat0], \n",
    "                    [clon0*clat0, slon0*clat0, slat0 ]])\n",
    "    \n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is reading the positions from the *.trans file that are within angle angDeg\n",
    "# of the vector vec.\n",
    "# It's saving the transformed lines of each tracklet into a dictionary.\n",
    "# This function should be doing the fitting too.\n",
    "#\n",
    "def select_positions(t_ref, r_func, vec, angDeg, lines, outfilename):\n",
    "    r_ref = r_func(t_ref)\n",
    "    r_name = \"_r%.1lf\" % (r_ref)\n",
    "\n",
    "    rot_mat = MPC_library.rotate_matrix(-MPC_library.Constants.ecl)\n",
    "\n",
    "    results_dict = defaultdict(list)\n",
    "    \n",
    "    vec = np.array(vec)\n",
    "    ecl_vec = np.dot(rot_mat, vec.T).T\n",
    "    vec = ecl_vec    \n",
    "    vec = vec/np.linalg.norm(vec)\n",
    "    mat = xyz_to_proj_matrix(vec)\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith('#'): \n",
    "            header = line.rstrip()\n",
    "            #outfile.write(header + '   desig       x_cor       y_cor        z_cor    dt \\n')\n",
    "        else:\n",
    "            lineID = line[:43]\n",
    "            trackletID = line[0:12]\n",
    "                \n",
    "            jd_tdb = float(line[43:57])\n",
    "            dtp = float(line[139:150])\n",
    "            x_cor, y_cor, z_cor = line[150:188].split()\n",
    "            r_cor = np.array([float(x_cor), float(y_cor), float(z_cor)])\n",
    "                \n",
    "            # Rotate to ecliptic coordinates\n",
    "            ecl_pos = np.dot(rot_mat, r_cor.T).T\n",
    "            r_cor = ecl_pos\n",
    "\n",
    "            if np.arccos(np.dot(vec, r_cor)/np.linalg.norm(r_cor))<angDeg*np.pi/180.:\n",
    "                xt, yt, zt = np.dot(mat, r_cor)/np.linalg.norm(r_cor)\n",
    "                results_dict[trackletID].append((jd_tdb-dtp, xt, yt, zt))\n",
    "\n",
    "    mxs, cxs, mys, cys = [], [], [], []\n",
    "    with open(outfilename, 'w') as outfile:\n",
    "        outstring = '#  radius = %lf\\n' % (r_ref)\n",
    "        outfile.write(outstring)\n",
    "        outstring = '#  angDeg = %lf\\n' % (angDeg)\n",
    "        outfile.write(outstring)\n",
    "        outstring = '#  vec= %lf, %lf, %lf\\n' % (vec[0], vec[1], vec[2])\n",
    "        outfile.write(outstring)\n",
    "        outfile.write('#  desig              alpha         alpha_dot       beta             beta_dot         dt \\n')\n",
    "        for k, v in results_dict.items():  \n",
    "            t = [obs[0]-t_ref for obs in v]\n",
    "    \n",
    "            x = [obs[1] for obs in v]\n",
    "            A = np.vstack([t, np.ones(len(t))]).T\n",
    "            mx, cx = np.linalg.lstsq(A, x)[0]\n",
    "            y = [obs[2] for obs in v]\n",
    "            my, cy = np.linalg.lstsq(A, y)[0]\n",
    "    \n",
    "            mxs.append(mx)\n",
    "            cxs.append(cx)\n",
    "            mys.append(my)\n",
    "            cys.append(cy)\n",
    "    \n",
    "            outstring = \"%12s %16.9lf %16.9lf %16.9lf %16.9lf %16.9lf\\n\" % (k, cx, mx, cy, my, t[0])\n",
    "            outfile.write(outstring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp_dict = defaultdict(list)\n",
    "infilename = 'itf_new_1_line_2457987.5_pm45.0_r2.5.trans'\n",
    "with open(infilename) as file:\n",
    "    for line in file:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        pix = int(line.split()[-1])\n",
    "        hp_dict[pix].append(line)\n",
    "                \n",
    "nside=8\n",
    "angDeg=5.0\n",
    "for i in range(hp.nside2npix(nside)):\n",
    "    vec = hp.pix2vec(nside, i, nest=True)\n",
    "    neighbors = hp.query_disc(32, vec, angDeg*np.pi/180., inclusive=True, nest=True)\n",
    "    lines = []\n",
    "    for pix in neighbors:\n",
    "        for line in hp_dict[pix]:\n",
    "            lines.append(line)\n",
    "    outfilename = infilename.rstrip('.trans') + '_hp_' + str(i)\n",
    "    select_positions(lunation_center(9), lambda x: 2.5, vec, angDeg, lines, outfilename)\n",
    "    #make_figure(outfilename)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trying a slightly different approach.\n",
    "# The set of lines that are being passed in have\n",
    "# been selected to be in the same region of sky\n",
    "# for an assumed distance.  We are going to re-transform\n",
    "# those assuming a fixed z (or gamma) value with respect\n",
    "# to the sun and the reference direction, rather than a \n",
    "# fixed r, at the reference time\n",
    "# \n",
    "# Rotate observatory positions to projection coordinates, \n",
    "# and recalculate simple z-based light-time correction.\n",
    "#\n",
    "# Rotate the observations to projection coordinates,\n",
    "# but they will be theta_x, theta_y only\n",
    "#\n",
    "# Fit the simple abg model, for fixed gamma and\n",
    "# possibly gamma_dot.\n",
    "#\n",
    "def select_positions_z(t_ref, z_func, vec, angDeg, lines, outfilename):\n",
    "    z_ref = z_func(t_ref)\n",
    "    z_name = \"_z%.1lf\" % (z_ref)\n",
    "\n",
    "    rot_mat = MPC_library.rotate_matrix(-MPC_library.Constants.ecl)\n",
    "\n",
    "    results_dict = defaultdict(list)\n",
    "    \n",
    "    vec = np.array(vec)\n",
    "    ecl_vec = np.dot(rot_mat, vec.T).T\n",
    "    vec = ecl_vec    \n",
    "    vec = vec/np.linalg.norm(vec)\n",
    "    mat = xyz_to_proj_matrix(vec)\n",
    "    \n",
    "    sep2 = angDeg*np.pi/180. * angDeg*np.pi/180.\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith('#'): \n",
    "            header = line.rstrip()\n",
    "        else:\n",
    "            lineID = line[:43]\n",
    "            trackletID = line[0:12]\n",
    "                \n",
    "            jd_tdb = float(line[43:57])\n",
    "            dtp = float(line[139:150])\n",
    "            \n",
    "            # Get unit vector to target\n",
    "            x_target, y_target, z_target = line[58:98].split()\n",
    "            r_target = np.array([float(x_target), float(y_target), float(z_target)])\n",
    "            \n",
    "            # Rotate to ecliptic coordinates\n",
    "            r_target_ec = np.dot(rot_mat, r_target.T).T\n",
    "            \n",
    "            # Rotate to projection coordinates\n",
    "            theta_x, theta_y, theta_z = np.dot(mat, r_target_ec)\n",
    "            # Ignore theta_z after this; it should be very nearly 1.\n",
    "            \n",
    "            if (theta_x*theta_x + theta_y*theta_y) < sep2:\n",
    "\n",
    "                # Get observatory position\n",
    "                x_obs, y_obs, z_obs = line[98:138].split()\n",
    "                r_obs = np.array([float(x_obs), float(y_obs), float(z_obs)])\n",
    "            \n",
    "                # Rotate to ecliptic coordinates\n",
    "                r_obs_ec = np.dot(rot_mat, r_obs.T).T\n",
    "            \n",
    "                # Rotate to projection coordinates            \n",
    "                xe, ye, ze = np.dot(mat, r_obs_ec)\n",
    "            \n",
    "                dlt = ze/MPC_library.Constants.speed_of_light\n",
    "                \n",
    "                results_dict[trackletID].append((jd_tdb, dlt, theta_x, theta_y, theta_z, xe, ye, ze))\n",
    "\n",
    "    mxs, cxs, mys, cys = [], [], [], []\n",
    "    with open(outfilename, 'w') as outfile:\n",
    "        outstring = '#  z_ref = %lf\\n' % (z_ref)\n",
    "        outfile.write(outstring)\n",
    "        outstring = '#  angDeg = %lf\\n' % (angDeg)\n",
    "        outfile.write(outstring)\n",
    "        outstring = '#  vec= %lf, %lf, %lf\\n' % (vec[0], vec[1], vec[2])\n",
    "        outfile.write(outstring)\n",
    "        outfile.write('#  desig              alpha         alpha_dot       beta             beta_dot         dt \\n')\n",
    "        for k, v in results_dict.items():  \n",
    "\n",
    "            t_emit = [obs[0]-obs[1]-t_ref for obs in v]\n",
    "            A = np.vstack([t_emit, np.ones(len(t_emit))]).T\n",
    "            \n",
    "            x = [obs[2] - obs[5]/z_func(obs[0]-t_ref) for obs in v]\n",
    "            mx, cx = np.linalg.lstsq(A, x)[0]\n",
    "            \n",
    "            y = [obs[3] - obs[6]/z_func(obs[0]-t_ref) for obs in v]\n",
    "            my, cy = np.linalg.lstsq(A, y)[0]\n",
    "    \n",
    "            mxs.append(mx)\n",
    "            cxs.append(cx)\n",
    "            mys.append(my)\n",
    "            cys.append(cy)\n",
    "    \n",
    "            outstring = \"%12s %16.9lf %16.9lf %16.9lf %16.9lf %16.9lf\\n\" % (k, cx, mx, cy, my, t_emit[0])\n",
    "            outfile.write(outstring)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp_dict = defaultdict(list)\n",
    "infilename = 'itf_new_1_line_2457987.5_pm45.0_r2.5.trans'\n",
    "with open(infilename) as file:\n",
    "    for line in file:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        pix = int(line.split()[-1])\n",
    "        hp_dict[pix].append(line)\n",
    "                \n",
    "nside=8\n",
    "angDeg=5.5\n",
    "for i in range(hp.nside2npix(nside)):\n",
    "    vec = hp.pix2vec(nside, i, nest=True)\n",
    "    neighbors = hp.query_disc(32, vec, angDeg*np.pi/180., inclusive=True, nest=True)\n",
    "    lines = []\n",
    "    for pix in neighbors:\n",
    "        for line in hp_dict[pix]:\n",
    "            lines.append(line)\n",
    "    outfilename = infilename.rstrip('.trans') + '_hp_' + str(i)\n",
    "    select_positions_z(lunation_center(9), lambda x: 2.5, vec, angDeg, lines, outfilename)\n",
    "    #make_figure(outfilename)\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a set of tracklets that are divided into healpix regions based on a heliocentric transformation,\n",
    "I can still scan through a set of z values for that selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp_dict = defaultdict(list)\n",
    "infilename = 'itf_new_1_line_2457987.5_pm45.0_r2.5.trans'\n",
    "with open(infilename) as file:\n",
    "    for line in file:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        pix = int(line.split()[-1])\n",
    "        hp_dict[pix].append(line)\n",
    "\n",
    "n=9\n",
    "nside=8\n",
    "angDeg=5.5\n",
    "z=2.4\n",
    "for i in range(hp.nside2npix(nside)):\n",
    "    vec = hp.pix2vec(nside, i, nest=True)\n",
    "    neighbors = hp.query_disc(32, vec, angDeg*np.pi/180., inclusive=True, nest=True)\n",
    "    lines = []\n",
    "    for pix in neighbors:\n",
    "        for line in hp_dict[pix]:\n",
    "            lines.append(line)\n",
    "    outfilename = infilename.rstrip('.trans') + '_z'+str(z)+'_hp_' + str(i)\n",
    "    select_positions_z(lunation_center(n), lambda x: z, vec, angDeg, lines, outfilename)\n",
    "    #make_figure(outfilename)\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp.nside2npix(nside)\n",
    "nside, 1.83*32/8*np.sqrt(2)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_figure(filename):\n",
    "    plt.ioff()\n",
    "    mxs, cxs, mys, cys =[], [], [], []\n",
    "    for line in open(filename):\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        desig, cx, mx, cy, my, dt = line.split()\n",
    "        mxs.append(float(mx))\n",
    "        cxs.append(float(cx))\n",
    "        mys.append(float(my))\n",
    "        cys.append(float(cy))\n",
    "    \n",
    "    fig=plt.figure(figsize=(18, 16))\n",
    "    plt.quiver(cxs, cys, mxs, mys, scale=1.0, width=0.0003)\n",
    "    plt.xlim(-0.2, 0.2)\n",
    "    plt.ylim(-0.2, 0.2)\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('beta')\n",
    "    outfile = filename+'.pdf'\n",
    "    plt.savefig(outfile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_figure('itf_new_1_line_2457987.5_pm45.0_r2.5_hp_764')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_figure('itf_new_1_line_2457987.5_pm45.0_r2.5_hp_759')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_figure('itf_new_1_line_2457987.5_pm45.0_r2.5_hp_765')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_figure('itf_new_1_line_2457987.5_pm45.0_r2.5_hp_766')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=-12\n",
    "hp_dict = defaultdict(list)\n",
    "infilename = 'UnnObs_Training_1_line_A_2457368.5_pm45.0_r2.5.trans'\n",
    "with open(infilename) as file:\n",
    "    for line in file:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        pix = int(line.split()[-1])\n",
    "        hp_dict[pix].append(line)\n",
    "                \n",
    "nside=8\n",
    "angDeg=5.5\n",
    "for i in range(hp.nside2npix(nside)):\n",
    "    vec = hp.pix2vec(nside, i, nest=True)\n",
    "    neighbors = hp.query_disc(32, vec, angDeg*np.pi/180., inclusive=True, nest=True)\n",
    "    lines = []\n",
    "    for pix in neighbors:\n",
    "        for line in hp_dict[pix]:\n",
    "            lines.append(line)\n",
    "    outfilename = infilename.rstrip('.trans') + '_hp_' + str(i)\n",
    "    select_positions_z(lunation_center(n), lambda x: 2.5, vec, angDeg, lines, outfilename)\n",
    "    #make_figure(outfilename)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_figure('UnnObs_Training_1_line_A_2457368.5_pm45.0_r2.5_hp_367')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2457368.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunation_center(-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
